---
title: "Advanced Biosurveillance"
author: "Jarad Niemi"
date: "`r Sys.Date()`"
output: 
  html_document:
    toc: true
  pdf_document:
    toc: true
vignette: >
  %\VignetteIndexEntry{Advanced Biosurveillance}
  %\VignetteEngine{knitr::rmarkdown}
---

If you shut down R, you will need to change your working directory and run the following commands to load libraries,

```{r, message=FALSE}
library('ggplot2')
library('dplyr')
library('tidyr')
library('RColorBrewer') 
library('ISDSWorkshop')
workshop(launch_index=FALSE)
```

Read in the data files and create additional columns. 

```{r}
# Read csv files and create additional columns
icd9df = read.csv("icd9.csv")
GI     = read.csv("GI.csv") %>%
  mutate(
    date      = as.Date(date),
    weekC     = cut(date, breaks="weeks"),
    week      = as.numeric(weekC),
    weekD     = as.Date(weekC),
    facility  = as.factor(facility),
    icd9class = factor(cut(icd9, 
                           breaks = icd9df$code_cutpoint, 
                           labels = icd9df$classification[-nrow(icd9df)], 
                           right  = TRUE)),
    ageC      = cut(age, 
                    breaks = c(-Inf, 5, 18, 45 ,60, Inf)),
    zip3      = trunc(zipcode/100))
```


# <a name="exporting_tables"></a> Exporting tables

There are many ways to export tables (for use in Word). Here I will cover two basic approachess that are simple and work well. 

- cut-and-paste
- create HTML table and cut-and-paste to Word

There are more sophisticated approaches that I will not cover:

- [using the rtf package](http://thomasleeper.com/Rcourse/Tutorials/wordoutput.html)
- [writing a whole doc fie in R](http://www.r-statistics.com/2013/03/write-ms-word-document-using-r-with-as-little-overhead-as-possible/)

## Cut-and-paste 

You can cut-and-paste directly from R. 

```{r}
ga_l <- GI %>%
  group_by(gender, ageC) %>%
  summarize(count = n())

ga_w <- ga_l %>%
  spread(ageC, count) %>%
  print(row.names = FALSE)
```

Cut-and-pasting this table is done in ASCII format. This looks good in a **plain text** document, e.g. Notepad, TextEdit, and some email, but will not look good in other formats, e.g. docx.


## Create HTML table

```{r}
library('xtable')
tab = xtable(ga_w,
             caption = "Total GI cases by Sex and Age Category",
             label   = "myHTMLanchor",
             align   = "ll|rrrrr") # rownames gets a column
```

Save the table to a file

```{r}
print(tab, file="table.html", type="html", include.rownames=FALSE)
```


## Output for this HTML table

The HTML code looks like 

```{r}
print(tab, type="html", include.rownames=FALSE)
```

and the resulting table looks like 

```{r, results='asis'}
print(tab, type="html", include.rownames=FALSE)
```


## Copy-and-paste table to Word

Now you can 

1. Open the file (`table.html`)
1. Copy-and-paste this table to Word. 


## Activity - exporting tables

Create a Word table for the number of cases by facility and age category.

```{r, eval=FALSE}
# Summarize data by facility and age category

# Reshape data from long to wide format

# Create HTML table

# Save HTML to file

# Copy-and-paste table into Word
```

When you have completed the activity, compare your results to the [solutions](04_biosurveillance-solution.html#exporting_tables).


# <a name="maps"></a> Maps

The packages `ggplot2` and `maps` can be used together to make maps.

Map of the continental US
```{r}
library('maps')
states = map_data("state")
ggplot(states, aes(x = long, y = lat, group = group)) + 
  geom_polygon(color="white")
```

Map of the counties in the continental US
```{r}
counties = map_data("county")
ggplot(counties, aes(x = long, y = lat, group = group)) + 
  geom_polygon(color = "white")
```

Map of the counties in Iowa
```{r}
ggplot(counties %>% filter(region=="iowa"), 
       aes(x = long, y = lat, group = group)) + 
  geom_polygon(fill = "gray", color = "black")
```

## Construct an appropriate data set

To make an informative map, we need to add data. 

```{r}
fluTrends = read.csv("fluTrends.csv", check.names=FALSE)
```

For simplicity, only keep the most recent 12 weeks on states. 

```{r}
nr = nrow(fluTrends)
flu_w = fluTrends[(nr-11):nr, c(1,3:53)]
dim(flu_w)
```

Reshape to long format

```{r}
flu_l <- flu_w %>%
  gather(region, index, -Date)
```

## Merge fluTrends data with map_data

The region names in `map_data` are lower case, so use `tolower()` to convert all the region names in flu_l to lowercase. Then the `map_data` and fluTrends data are merged using `merge()`. 

```{r}
head(unique(states$region))
flu_l$region = tolower(flu_l$region)
states_merged = merge(states, flu_l, sort=FALSE, by='region')
```

## Make the plots

Some Google Flu Trend data.

```{r}
states_merged$Date = as.Date(states_merged$Date)
mx_date = max(states_merged$Date)
ggplot(states_merged %>% filter(Date == mx_date), 
       aes(x = long, y = lat, group = group, fill = index)) + 
  geom_polygon() + 
  labs(title=paste('Google Flu Trends on', mx_date), x='', y='') +
  theme_minimal() + 
  theme(legend.title = element_blank()) +
  coord_map("cylindrical") + 
  scale_fill_gradientn(colours=brewer.pal(9,"Reds")) # Thanks Annie Chen
```

Last 12 weeks.

```{r}
ggplot(states_merged, 
       aes(x=long, y=lat, group=group, fill=index)) + 
  geom_polygon() + 
  labs(title='Google Flu Trends', x='', y='') +
  theme_minimal() + 
  theme(legend.title = element_blank()) +
  facet_wrap(~Date) + 
  coord_map("cylindrical") + 
  scale_fill_gradientn(colours=brewer.pal(9,"Reds")) 
```


## Activity 

Modify the code to determine what elements of the map are affected.

Advanced: Download the data directly from <http://www.google.org/flutrends/about/data/flu/historic/us-historic-v3.txt> using `read.csv' and then construct a map of the most recent Google Flu Trends data. 

```{r, eval=FALSE}
# Construct Google Flu Trends map
```

When you have completed the activity, compare your results to the [solutions](04_biosurveillance-solution.html#maps).



# <a name="Packages"></a> Packages

A package provides additional functionality besides what base installation of R provides. You have already used a number of additional packages:

- ggplot2
- ISDSWorkshop
- maps
- dplyr
- tidyr
- xtable

The Comprehensive R Archive Network (CRAN) has over 9,594 packages. 
These packages can be installed using the `install.packages()` function, e.g. 

```{r, eval=FALSE}
install.packages("ggplot2")
```

For many reasons, packages may not be on CRAN but may be available from other sources:

- [Github](http://github.com/)
- [Bioconductor](http://www.bioconductor.org/)
- Source file (tar.gz)


## Github

To install a package from github, you can use the `install_github()` function from the `devtools` package. For example,

```{r, eval=FALSE}
# install.packages("devtools")
library('devtools')
install_github('nandadorea/vetsyn')
```


## Bioconductor 

Bioconductor provides tools for high-throughput genomic data. There are over 900 packages available from bioconductor. To install bioconductor, use 

```{r, eval=FALSE}
source("http://bioconductor.org/biocLite.R")
biocLite()
```

Then to install a package from bioconductor use 

```{r, eval=FALSE}
biocLite("edgeR")
```

The bioconductor repository may be useful in the future for public health biosurveillance.


## Source

All packages can be installed from their source. If a package is not available in a repository, then this is the only way to install the package. To install from source download the source file (.tar.gz) and then use the `install.packages()` function with arguments `repos=NULL` and `type="source"`. For example, from a source version of this workshop, you would use the following command:

```{r, eval=FALSE}
install.packages("ISDSWorkshop_0.2.tar.gz", 
                 repos = NULL, 
                 type  = "source")
```



## Packages for surveillance

Some [packages for performing surveillance](http://www.ij-healthgeographics.com/content/9/1/16) are 

- [accrued](http://cran.r-project.org/web/packages/accrued/index.html)
- [Epi](http://cran.r-project.org/web/packages/Epi/index.html)
- [SpatialEpi](http://cran.r-project.org/web/packages/SpatialEpi/index.html)
- [surveillance](http://cran.r-project.org/web/packages/surveillance/index.html)
- [vetsyn](https://github.com/nandadorea/vetsyn)


## SpatialEpi - Kulldorff example

The `SpatialEpi` package implements the Kulldorff cluster detection method in the `kulldorff()` function. 

Setting up the analysis (taken directly from the example)
```{r}
library('SpatialEpi')

## Load Pennsylvania Lung Cancer Data
data(pennLC)
data <- pennLC$data

## Process geographical information and convert to grid
geo <- pennLC$geo[,2:3]
geo <- latlong2grid(geo)

## Get aggregated counts of population and cases for each county
population <- tapply(data$population, data$county, sum)
cases      <- tapply(data$cases,      data$county, sum)

## Based on the 16 strata levels, compute expected numbers of disease
n.strata       <- 16
expected.cases <- expected(data$population, data$cases, n.strata)

## Set Parameters
pop.upper.bound <- 0.5
n.simulations   <- 999
alpha.level     <- 0.05
plot            <- TRUE
```

## SpatialEpi - Kulldorff example

Plot the data

```{r}
clr = cases/population
clr = 1-clr/max(clr) # make sure range is (0,1)
plot(pennLC$spatial.polygon, axes=TRUE, col=rgb(1, clr, clr))
```

## SpatialEpi - Kulldorff example

Run the analysis and plot the results (directly from the example)

```{r}
## Kulldorff using Binomial likelihoods
binomial <- kulldorff(geo, cases, population, NULL, pop.upper.bound, n.simulations, 
  alpha.level, plot)
cluster <- binomial$most.likely.cluster$location.IDs.included

## plot
plot(pennLC$spatial.polygon,axes=TRUE)
plot(pennLC$spatial.polygon[cluster],add=TRUE,col="red")
title("Most Likely Cluster")
```


## Activity - Install the `surveillance` package

If you are connected to the internet, try installing the `surveillance` package. 
If you are successful, look at its help file.

```{r, eval=FALSE}
# Install the surveillance package
```


When you have completed the activity, compare your results to the [solutions](04_biosurveillance-solution.html#packages).





# <a name="functions"></a> Functions

Packages are typically a collection of functions. But you can write your own. For example,

```{r}
add = function(a,b) {
  return(a+b)
}
add(1,2)
```

or 

```{r}
add_vector = function(v) {
  sum = 0
  for (i in 1:length(v)) sum = sum + v[i]
  return(sum)
}
```

## A simple outbreak detection function

Here is a simple outbreak detection function

```{r}
alert = function(y,threshold=100) {
  # y is the time series 
  # an alert is issue for any y above the threshold (default is 100)
  factor(ifelse(y>threshold, "Yes", "No"))
}
```

Run this on our weekly GI data.

```{r}
GI_w <- GI %>%
  group_by(weekD) %>%
  summarize(count = n())

GI_w$alert = alert(y = GI_w$count, threshold = 150)

ggplot(GI_w, aes(x = weekD, y = count, color = alert)) + 
  geom_point() + 
  scale_color_manual(values = c("black","red"))
```


# <a name="batch"></a> R in batch

For routine analysis, it can be helpful to run R in batch mode rather than interactively. To do this, create a script and save the script with a .R extension, e.g. `script.R`:

```{r, eval=FALSE}
# Read in the data perhaps as a csv file

# Create some table and save them to html files

# Create some figures and save them to jpegs

# Run some outbreak detection algorithms and produce figures
```

Now, from the command line run

    Rscript script.R
    
Now each week you can update the csv file and then just run the script which will create all new tables and figures. 


# <a name="shiny"></a> Shiny apps

R can be used to create HTML applications through the `shiny` package. 
The code is written entirely in R, although you can use cascading style sheets (CSS) if you want to update how it looks. 
[Here is an example](https://michaud.shinyapps.io/CDCPlot/) that allows visualization of CDC data.

These apps can also be run locally, e.g.

```{r, eval=FALSE}
install.packages('shiny')
library(shiny)
runGitHub('NLMichaud/WeeklyCDCPlot')
```
